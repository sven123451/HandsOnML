{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Artificial Neural Networks with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly for future reference, when should you use Keras or TensorFlow for building neural networks\n",
    "\n",
    "    Keras:\n",
    "        \n",
    "        Very easy to use, great for beginners\n",
    "\n",
    "        Limited to high-level APIs\n",
    "\n",
    "        Less control over low-level details\n",
    "        \n",
    "        For prototyping and standard models\n",
    "\n",
    "        Runs on top of Tensorflow\n",
    "    \n",
    "    Tensorflow\n",
    "\n",
    "        Steeper learning curve, more complex\n",
    "\n",
    "        Highly flexible, supports custom workflows\n",
    "\n",
    "        Full control over every aspect of the model\n",
    "\n",
    "        Research, custom models, production\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANNs and Examples\n",
    "\n",
    "ANNs are ML models that are inspired by the networks of biological neurons found in our brains. ANNs are at the very core of deep learning. They are versatile, powerful, and scalable, making them ideal to tackle large and highly complex machine learning tasks such as classifying billions of images, powering speech recognition services, recommending the best videos to watch to hundreds of millions of users every day, or learning to beat the world champion at the game of go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perceptron is one of the simples ANN architectures, invented in 1957 by Frank Rosenblatt. It is based on a slightly different artiical neuron called a threshold logic unit (TLU), or sometimes a linear threshold unit (LTU). The inputs and output are numbers (instead of binary on/off values), and each input connection is associated with a weight. The TLU first computes a linear function of its inputs, then it applies a step function to the result. So we can see it almost like logistic regression, except it uses a step function instead of the logistic function. Just like in logistic regression, the model parameters are the input weights w and the bias term b. \n",
    "\n",
    "A single TLU can be used for simple linear binary classification, it computes a linear function of its inputs, and if the result exceeds a threshold, it outputs the positive class. A perceptron is composed of one of more TLUs organized in a single layer, where every TLU is connected to every input. This layer is called a fully connected layer or dense layer. The inputs constitute the input lyaer, and since the layer of TLUs produces the final outputs, it is called the output layer. For example, a  perceptron with 2 inputs and 3 TLUs could classify instances simultaneouslt into three different binary classes, making it a multilabel classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "y = (iris.target == 0) #Iris setosa\n",
    "\n",
    "per_clf = Perceptron(random_state = 42)\n",
    "per_clf.fit(X,y)\n",
    "X_new = [[2,0.5],[3,1]]\n",
    "y_pred = per_clf.predict(X_new) # predicts True and False for these 2 flowers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Multilayer Perceptron and Backpropagation\n",
    "\n",
    "Some of the limitations of perceptrons can eb elimated by stacking multiple perceptrons (layers). The resulting ANN is called a multilayer perceptron (MLP). An MLP is composed of one input layer, one or more layers of TLUs called hidden layers, and one final layer of TLUs called the output layer. The layers close to the input are usually called the lower layers, and the ones close to the outputs are usually called the upper layers.\n",
    "\n",
    "When an ANN contains a deep stack of hidden layers, it is called a deep neural network (DNN). The field of deep learning studies DNNs, and more generally it is interested in models containing deep stacks of computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So then, how are MLP Models Trained?\n",
    "\n",
    "For many years MLPs could not be created as researchers failed to find ways to train them. At first gradient descent was proposed, which computed the gradients of the model's error with regard to model parameters, however this was unfeasible with computational limitations and no clear method of doing so.\n",
    "\n",
    "Then, the reverse-mode automatic differentiation algorithm was proposed. The reverse mode auto diff can compute the gradients of the neural network's error with regard to every single model parameter in just two passes (one forward, one backward) of the network. In other words, it can find out how each connection weight/bias should be tweaked in order to reduce the neural network's error. These gradients can then be used to perform a gradient descent step. If you repeat this process of computing the gradients automatically and taking a gradient descent step, the neural network's error will gradually drop until it eventually reaches a minimum. This combination of reverse-mode autodiff and gradient descent is now called backpropagation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation Step by Step\n",
    "\n",
    "    Handles one mini-batch at a time (for example containing 32 instances each), and it goes through the full training set multiple times. Each pass is called an epoch.\n",
    "\n",
    "    Each mini-batch enters the network through the input layer. The algorithm then computes the output of all the neurons in the first hidden layer, for every instance in the mini-batch. The result is apsssed onto the next layer, its output is computed etc. until we get the ouput of the output layer. This is the forward-pass, it is exactly like making predictions, except all intermediate results are preserved since they are needed for the backwards pass.\n",
    "\n",
    "    Next, the backprop algorithm measures the network's output error (ie, using a loss function that computes the desired output and actual output of the nerwork, returning some measure of the error).\n",
    "\n",
    "    Then it computes how much each output bias and connection to the output layer contributed to the error. The algorithm subsequently measures how much each of these error contributions came from each connection in the layer below, again using the chain rule, working backwards until it raches the input layer. \n",
    "\n",
    "    This reverse pass efficiently measures the error gradient across all the connection weights and biases in the network by propagating the error gradient backward through the network.\n",
    "\n",
    "    Finally, the algorithm performs a gradient descent step to tweak all the connection weights in the network, using the error gradients it just computed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression MLPs\n",
    "\n",
    "First, MLPs can be used for regression tasks. If you want to predict a single vlaue (e.g the price of a house, given many of its features), then you just need a single output neuron: its output is the predicted value. \n",
    "\n",
    "For multivariate regression (i.e to predict multiple values at once), you need one output neuron per output dimension. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25536110312136884\n",
      "0.5053326657968678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#Fetching and splitting the dataset\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state = 42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state = 42)\n",
    "#creates a pipeline to standardize the input features before sending them to \n",
    "#MLP regressor, in practice this would be feature engineering\n",
    "#this step is important for neural networks because they are trained using\n",
    "#gradient descent, which does not converge well when features have different scales\n",
    "\n",
    "mlp_reg = MLPRegressor(hidden_layer_sizes=[50,50,50], random_state=42)\n",
    "pipeline = make_pipeline(StandardScaler(), mlp_reg)\n",
    "\n",
    "#we then train the model and evaluate its validation error\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_valid)\n",
    "mse = mean_squared_error(y_valid, y_pred)\n",
    "print(mse)\n",
    "\n",
    "rmse = mse ** 0.5\n",
    "\n",
    "print(rmse)\n",
    "\n",
    "#Continue from p.g 314"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP regressor uses ReLU activation functions for the hidden layers, but fails to use it on the output layer. This is a limitation of the MLPRegressor class as it does not support any activation functions on the output layer. This is why scikit-learn is not optimal for creating these kinds of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing MLPs with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is TensorFlow's high-lelve deep learning API, allowing you to build, train, evaluate, and execute all sorts of neural networks. The first MLP we will build with Keras is a Classification MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Classification MLP?\n",
    "\n",
    "MLPs can handle both binary and multilabel classification tasks. For example an email classifcation system that predicts whether each email is ham or spam, and also whether it is urgent or nonurgent. \n",
    "\n",
    "If each instance (input) can only belong to a single class, out of 3 or more possible classes (e.g 0-9 for image of numbers classification), we need to have one output neuron per class, and we should use the softmax activation function for the whole output layer.\n",
    "\n",
    "    Softmax Function: Activation function which ensures that all estimated probabilities are between 0 and 1, and that they add up to 1, since the calsses are exclusive. This achieves the same end goal as our multiclass classification in Chapter 3. \n",
    "\n",
    "For our loss function, we should use the cross-entropy loss (x-entropy) function as we are predicting probability distributions.\n",
    "\n",
    "    Interpretation: Cross-entropy measures the \"distance\" between the true distribution and the predicted distribution in terms of probability.\n",
    "\n",
    "    Probabilistic Output: The softmax function ensures that the output is a valid probability distribution (sums to 1), making it natural to use cross-entropy.\n",
    "\n",
    "    Focus on Correct Class: The loss strongly penalizes incorrect predictions and rewards high confidence in correct predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an Image Classifier Using the Sequential API (Keras and Fashion MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Fashion MNIST is a drop-in replacement of MNIST, where the images represent fashion items rather than handwritten digits. This makes the classification task far more complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#The dataset is already shuffled and split into training and test sets, so we just need to hold out on the last 5,000 images\n",
    "#from the training set to use as a validation set\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "#tensorflow is usually imported as tf, and the Keras API is available via tf.keras\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n",
    "\n",
    "#For simplicity, we'll scale the pixel intensities down to the 0-1 range by dividing them by 255.0 (this also converts them to floats)\n",
    "X_train, X_valid, X_test = X_train / 255., X_valid / 255., X_test/255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We first manually define a list of class names that correspond to the \n",
    "#numerical labels in the Fashion MNIST dataset\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "#y_train[0] gets the numerical label of the first training image (9)\n",
    "#we use this number as an index into class_names which returns Ankle boot\n",
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Creating the model using the sequential API\n",
    "\n",
    "tf.random.set_seed(42) #sets random seed for tensorflow\n",
    "# tf.keras.utils.set_random_seed() is an alternative which sets the randomseed for Tensorflow, \n",
    "#python and NumPy\n",
    "\n",
    "#Sequential model is the simplest kind of Keras model for neural networks only composed of a \n",
    "#single stack of layers connected sequentially. This is called the sequential APi\n",
    "model = tf.keras.Sequential()\n",
    "#next we build the input layer and add it to the model\n",
    "model.add(tf.keras.layers.Input(shape=[28,28]))\n",
    "model.add(tf.keras.layers.Flatten()) #flatten layer converts each input image to a 1d array\n",
    "#Dense layers have a certain amount of neurons and an activation function\n",
    "#Each layer manages its own weight matrix, containing all the connection weights between the \n",
    "#neurons and their inputs\n",
    "#It also manages a vector of bias terms (one per neuron)\n",
    "model.add(tf.keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.summary() #This method displays all the model's layers, including each layer's name\n",
    "#and it's number of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that dense layers often have a lot of parameters, For example the first hidden layer (dense) has 784 x 300 connection weights, plus 300 bias terms, which adds up to 235,500 parameters. This gives the model quite a lot of flexibility to fit the training data, but also means the model runs the risk of overfitting, especially when we don't have a lot of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can get a model's list of layers using the layers attribute, or using the\n",
    "#get_layer() method to access a layer by name\n",
    "\n",
    "model.layers\n",
    "\n",
    "hidden1 = model.layers[1] #in our case, the layer with index 1 in model is dense_3 as we \n",
    "#created other neural networks previously, this will change depending \n",
    "# on the order that you run the code\n",
    "\n",
    "hidden1.name\n",
    "\n",
    "model.get_layer('dense_3') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Instead of adding the layers one by one as in the previous example, it's often more convenient \n",
    "#to pass a list of layers when creating the Sequential model. You can also drop the Input layer\n",
    "#and instead specify the input_shape in the first layer:\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28,28]),\n",
    "    tf.keras.layers.Dense(300, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01905416, -0.0135011 ,  0.03682976, ..., -0.03432151,\n",
       "         0.02697493, -0.06716153],\n",
       "       [ 0.06210591, -0.02984376, -0.02164529, ...,  0.03889368,\n",
       "         0.03622238,  0.06468654],\n",
       "       [-0.05059826, -0.04985394,  0.02094979, ..., -0.04002566,\n",
       "         0.04765008,  0.0345116 ],\n",
       "       ...,\n",
       "       [-0.05960568, -0.06183277, -0.06904332, ..., -0.07217256,\n",
       "        -0.06044647, -0.06770536],\n",
       "       [ 0.03972965,  0.06005622, -0.02595117, ...,  0.00392867,\n",
       "         0.06451987,  0.056135  ],\n",
       "       [ 0.07380764,  0.01734012, -0.0536403 , ...,  0.01524645,\n",
       "         0.01778628, -0.02953833]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All parameters of a layer can be accessed using the get_weights() and set_weights() methods.\n",
    "#For a dense layer as in our Sequential model, this includes both connection weights/bias term\n",
    "\n",
    "weights, biases = hidden1.get_weights() #get_weights returns arrays of biases, weights\n",
    "\n",
    "weights #we seperate them into weights and biases respectively and then we can inspect them\n",
    "weights.shape\n",
    "\n",
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After the model is created, you must call its compile() method to specify the loss function\n",
    "#and the optimizer to use. Optionally, you can specify a list of extra metrics to compute\n",
    "#during training and evaluation\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer='sgd',\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the 'sparse_categorical_crossentropy' loss function because we have sparse labels (i.e, for each instance, there is just a target class index from 0- and the classes are exclusive). If instead we had one target probability per class for each instance (e.g one-hot vectors) then we would need to use the 'categorical_crossentropy' loss instead. If we were doing binary classification or multilabel binary classification, then we would use the 'sigmoid' activation function in the output layer instead of the softmax activation function, and we would use the binary_crossentropy loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - accuracy: 0.6722 - loss: 1.0187 - val_accuracy: 0.8216 - val_loss: 0.5233\n",
      "Epoch 2/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 0.8231 - loss: 0.5136 - val_accuracy: 0.8354 - val_loss: 0.4698\n",
      "Epoch 3/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - accuracy: 0.8402 - loss: 0.4583 - val_accuracy: 0.8454 - val_loss: 0.4437\n",
      "Epoch 4/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - accuracy: 0.8501 - loss: 0.4273 - val_accuracy: 0.8484 - val_loss: 0.4240\n",
      "Epoch 5/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 0.8585 - loss: 0.4052 - val_accuracy: 0.8544 - val_loss: 0.4097\n",
      "Epoch 6/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - accuracy: 0.8641 - loss: 0.3879 - val_accuracy: 0.8586 - val_loss: 0.3987\n",
      "Epoch 7/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - accuracy: 0.8687 - loss: 0.3735 - val_accuracy: 0.8590 - val_loss: 0.3894\n",
      "Epoch 8/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.8726 - loss: 0.3609 - val_accuracy: 0.8620 - val_loss: 0.3819\n",
      "Epoch 9/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - accuracy: 0.8764 - loss: 0.3497 - val_accuracy: 0.8648 - val_loss: 0.3762\n",
      "Epoch 10/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - accuracy: 0.8797 - loss: 0.3396 - val_accuracy: 0.8680 - val_loss: 0.3717\n",
      "Epoch 11/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 0.8828 - loss: 0.3302 - val_accuracy: 0.8678 - val_loss: 0.3675\n",
      "Epoch 12/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - accuracy: 0.8860 - loss: 0.3214 - val_accuracy: 0.8696 - val_loss: 0.3637\n",
      "Epoch 13/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - accuracy: 0.8884 - loss: 0.3130 - val_accuracy: 0.8698 - val_loss: 0.3601\n",
      "Epoch 14/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - accuracy: 0.8909 - loss: 0.3053 - val_accuracy: 0.8702 - val_loss: 0.3584\n",
      "Epoch 15/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - accuracy: 0.8930 - loss: 0.2981 - val_accuracy: 0.8704 - val_loss: 0.3577\n",
      "Epoch 16/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 0.8951 - loss: 0.2914 - val_accuracy: 0.8706 - val_loss: 0.3569\n",
      "Epoch 17/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682us/step - accuracy: 0.8975 - loss: 0.2852 - val_accuracy: 0.8702 - val_loss: 0.3563\n",
      "Epoch 18/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - accuracy: 0.8996 - loss: 0.2790 - val_accuracy: 0.8692 - val_loss: 0.3559\n",
      "Epoch 19/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - accuracy: 0.9016 - loss: 0.2734 - val_accuracy: 0.8694 - val_loss: 0.3558\n",
      "Epoch 20/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678us/step - accuracy: 0.9044 - loss: 0.2678 - val_accuracy: 0.8724 - val_loss: 0.3548\n",
      "Epoch 21/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 0.9060 - loss: 0.2625 - val_accuracy: 0.8720 - val_loss: 0.3562\n",
      "Epoch 22/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - accuracy: 0.9082 - loss: 0.2574 - val_accuracy: 0.8722 - val_loss: 0.3553\n",
      "Epoch 23/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - accuracy: 0.9101 - loss: 0.2524 - val_accuracy: 0.8724 - val_loss: 0.3560\n",
      "Epoch 24/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - accuracy: 0.9122 - loss: 0.2479 - val_accuracy: 0.8732 - val_loss: 0.3541\n",
      "Epoch 25/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.9134 - loss: 0.2433 - val_accuracy: 0.8740 - val_loss: 0.3555\n",
      "Epoch 26/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 0.9158 - loss: 0.2388 - val_accuracy: 0.8756 - val_loss: 0.3559\n",
      "Epoch 27/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.9170 - loss: 0.2347 - val_accuracy: 0.8762 - val_loss: 0.3548\n",
      "Epoch 28/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.9184 - loss: 0.2306 - val_accuracy: 0.8774 - val_loss: 0.3533\n",
      "Epoch 29/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - accuracy: 0.9202 - loss: 0.2264 - val_accuracy: 0.8766 - val_loss: 0.3534\n",
      "Epoch 30/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.9220 - loss: 0.2225 - val_accuracy: 0.8786 - val_loss: 0.3525\n"
     ]
    }
   ],
   "source": [
    "#Now that we have built and compiled the model, we can train it using it's fit() method\n",
    "#the fit method returns a history object containing the training parameters (history.params)\n",
    "#the list of epochs it went through (history.epoch), and most importantly a dictionary\n",
    "#containing the loss and extra metrics it measured at the end of each epoch on the training\n",
    "#and validation set\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Epoch'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We can use the history.history attribute to create a pandas dataframe and call its plot()\n",
    "#method to get the learning curves\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(\n",
    "    figsize=(8,5), xlim=[0,29], ylim=[0,1], grid=True, xlabel =\"Epoch\",\n",
    "    style=[\"r--\",\"r--\",\"b-\",\"b-*\"])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that both the training accuracy and the validation accuracy steadily increase during training, while the training loss and the validation loss decrease. This is good. The validation curves are relatively close to each other at first, but they get further apart over time, which shows that there's a little bit of overfitting. In this particular case, the model looks like it performed better on the validation set than on the training set at the beginning of training, but that's not the case. The validation error is computed at the end of each epoch, so the training curve should be shifted by half an epoch to the left.\n",
    "\n",
    "The training set performance ends up beating the validation eprformance, as is generally the case when you train for long enough. You can tell that the model has not quite converged yet, as the validation loss is still going down, so you should probably continue training. We can do this by simpl calling the fit() method again on the same model, since Keras just continues training where it left off: you should be able to reach about 89.8% validation accruacy, while the training accuracy will continue to rise up to 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweaking and Evaluating a NN\n",
    "\n",
    "If you are not satisfied with the performance of your model, you should go back and tune the hyperparameters. The first one being the learning rate. If that doesn't help, try another optimizer (and always retune the learning rate after changing any hyperparameter). If the performance is still not geat, then try tuning model hyperparameters such as the number of layers, the number of neurons per layer, and the types of activation functions to use for each hidden layer.\n",
    "\n",
    "You can also try tuning other hyperparameters, such as the batch size (set in the fit() method using the batch_size argument). Once you are satisfied with your model's validation accuracy, you should evaluate it on the test set to estimate the generalization error before you deploy the model to production. You do this by using the evaluate() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - accuracy: 0.8731 - loss: 0.3716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37162983417510986, 0.8737000226974487]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "\n",
    "#remember to resist the temptation to tweak the hyperparameters on the test set, or else your \n",
    "#estimate of the generalization error will be too optimistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the model to make predictions\n",
    "\n",
    "Now that we have evaluated the model, we can use the predict() method to make predictions on new instances. Since we don't have actual new instances, we'll just use the first three instances of the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.31, 0.  , 0.02, 0.  , 0.67],\n",
       "       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)\n",
    "\n",
    "#For each instance (subarray) the model estimates one probability per class of object\n",
    "#If we only care about the class with the highest estimated probability (even if it is quite low)\n",
    "#then you can use the argmax method to get highest probability class index for each instance\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "y_pred = y_proba.argmax(axis=-1)\n",
    "y_pred\n",
    "np.array(class_names)[y_pred]\n",
    "\n",
    "#CONTINUE FROM 329"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving a trained Keras model is simple\n",
    "\n",
    "model.save(\"my_model.keras\")\n",
    "#You will typically have a script that trains a model and saves it, and one or more scripts\n",
    "#that load the model and use it to evaluate it or to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can then load the model using the following code\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(\"my_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Summary, we built the Sequential classifier using the following steps. \n",
    "\n",
    "    First, load and preprocess the data by splitting it into training, validation, and test sets (using train_test_split or manual splitting) and scaling the pixel values to the 0-1 range by dividing by 255. \n",
    "    \n",
    "    Then, build the model using tf.keras.Sequential(), adding layers in sequence - typically starting with a Flatten layer to convert 2D image data to 1D, followed by Dense layers with ReLU activation functions for hidden layers, and a final Dense layer with softmax activation for classification output. \n",
    "    \n",
    "    Next, compile the model by specifying the loss function (e.g., 'sparse_categorical_crossentropy' for classification), optimizer (e.g., 'sgd'), and metrics (e.g., 'accuracy') using model.compile(). \n",
    "    \n",
    "    Train the model using model.fit(), providing the training data, number of epochs, and validation data. \n",
    "    \n",
    "    Finally, evaluate the model's performance on the test set using model.evaluate(), and once satisfied, use model.predict() to make predictions on new data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
